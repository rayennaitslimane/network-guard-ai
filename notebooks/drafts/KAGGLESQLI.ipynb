{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINE TUNING DISTILBERT (HUGGING FACE PRETRAINED TRANSFORMER) TO DETECT SQL INJECTIONS\n",
    "### Rayen NAIT SLIMANE - Masters Student ISIMA INP\n",
    "\n",
    "**NOTE:** This notebook is designed to run on [Kaggle](kaggle.com) with the [SQL-Injection-Dataset](https://www.kaggle.com/datasets/sajid576/sql-injection-dataset/data).\n",
    "Make sure to enable the P100 GPU (free 30h/week quota) for optimal performance during training.\n",
    "\n",
    "I propose fine-tuning DistilBERT, a high-efficiency transformer model, to deliver an AI-powered SQL Injection (SQLi) detection solution. This project will quickly evaluate the model's performance against a Kaggle dataset to establish the most effective and resource-lean strategy for eliminating SQLi vulnerabilities. The goal is to deploy a cutting-edge, high-accuracy defense faster than traditional methods allow.\n",
    "\n",
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T01:00:59.126448Z",
     "iopub.status.busy": "2025-10-13T01:00:59.125835Z",
     "iopub.status.idle": "2025-10-13T01:01:02.549655Z",
     "shell.execute_reply": "2025-10-13T01:01:02.548858Z",
     "shell.execute_reply.started": "2025-10-13T01:00:59.126413Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install transformers datasets torch evaluate scikit-learn tensorboard -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T01:01:37.370936Z",
     "iopub.status.busy": "2025-10-13T01:01:37.370033Z",
     "iopub.status.idle": "2025-10-13T01:01:37.375122Z",
     "shell.execute_reply": "2025-10-13T01:01:37.374336Z",
     "shell.execute_reply.started": "2025-10-13T01:01:37.370911Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import (\n",
    "    DistilBertTokenizer,\n",
    "    DistilBertForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T01:01:41.127944Z",
     "iopub.status.busy": "2025-10-13T01:01:41.127636Z",
     "iopub.status.idle": "2025-10-13T01:01:41.133025Z",
     "shell.execute_reply": "2025-10-13T01:01:41.132160Z",
     "shell.execute_reply.started": "2025-10-13T01:01:41.127915Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0+cu124\n",
      "CUDA available: True\n",
      "CUDA device: Tesla P100-PCIE-16GB\n",
      "Number of GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "# Check GPU availability\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T01:01:52.483950Z",
     "iopub.status.busy": "2025-10-13T01:01:52.483422Z",
     "iopub.status.idle": "2025-10-13T01:01:52.535880Z",
     "shell.execute_reply": "2025-10-13T01:01:52.535225Z",
     "shell.execute_reply.started": "2025-10-13T01:01:52.483924Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/kaggle/input/sql-injection-dataset/Modified_SQL_Dataset.csv')\n",
    "df = df.rename(columns={'Query': 'text', 'Label': 'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T01:01:55.642089Z",
     "iopub.status.busy": "2025-10-13T01:01:55.641370Z",
     "iopub.status.idle": "2025-10-13T01:01:55.680499Z",
     "shell.execute_reply": "2025-10-13T01:01:55.679920Z",
     "shell.execute_reply.started": "2025-10-13T01:01:55.642065Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# First split: 80% train+val, 20% test\n",
    "train_val_df, test_df = train_test_split(\n",
    "    df, test_size=0.2, random_state=42, stratify=df['label']\n",
    ")\n",
    "\n",
    "# Second split: 80% train, 20% validation (of the train_val set)\n",
    "train_df, val_df = train_test_split(\n",
    "    train_val_df, test_size=0.2, random_state=42, stratify=train_val_df['label']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T01:01:59.616914Z",
     "iopub.status.busy": "2025-10-13T01:01:59.616389Z",
     "iopub.status.idle": "2025-10-13T01:01:59.649798Z",
     "shell.execute_reply": "2025-10-13T01:01:59.649246Z",
     "shell.execute_reply.started": "2025-10-13T01:01:59.616890Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "raw_dataset = DatasetDict({\n",
    "    'train': Dataset.from_pandas(train_df.reset_index(drop=True)),\n",
    "    'validation': Dataset.from_pandas(val_df.reset_index(drop=True)),\n",
    "    'test': Dataset.from_pandas(test_df.reset_index(drop=True))\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tokenizer/Model Loading & Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T01:02:02.926027Z",
     "iopub.status.busy": "2025-10-13T01:02:02.925355Z",
     "iopub.status.idle": "2025-10-13T01:02:17.958393Z",
     "shell.execute_reply": "2025-10-13T01:02:17.957595Z",
     "shell.execute_reply.started": "2025-10-13T01:02:02.926002Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f5bedb8e0fb4e1290ba9d36eb2f6d50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aef84ad28e045ffa4320d92108896d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4c1543b43df46b59c637402d2bcef4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa101dc3c2de487690521d6ac3f7f8fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5aeddb8f2fc4fe4b998a48e2ab9e6e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19788 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0206cb872de64b7ab5601443bf9cdb1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4947 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b61448ce148478da1ccaf849553eff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6184 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the DistilBERT tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# Define preprocessing function\n",
    "def preprocess_function(examples):\n",
    "    \"\"\"\n",
    "    Tokenize the input text (SQL queries) with padding and truncation\n",
    "    \"\"\"\n",
    "    return tokenizer(\n",
    "        examples['text'], \n",
    "        padding=\"max_length\", \n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "encoded_dataset = raw_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T01:02:25.536950Z",
     "iopub.status.busy": "2025-10-13T01:02:25.536341Z",
     "iopub.status.idle": "2025-10-13T01:02:27.871724Z",
     "shell.execute_reply": "2025-10-13T01:02:27.871098Z",
     "shell.execute_reply.started": "2025-10-13T01:02:25.536928Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "877550a77be04225b7889486ad1422ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load DistilBERT for sequence classification\n",
    "# num_labels=2 for binary classification (benign vs malicious SQL queries)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\", \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T01:05:40.409811Z",
     "iopub.status.busy": "2025-10-13T01:05:40.409528Z",
     "iopub.status.idle": "2025-10-13T01:05:40.436733Z",
     "shell.execute_reply": "2025-10-13T01:05:40.436184Z",
     "shell.execute_reply.started": "2025-10-13T01:05:40.409790Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define training arguments - optimized for speed and performance (<10 min training)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/kaggle/working/results\",\n",
    "    eval_strategy=\"epoch\",                     # Evaluate once at end - faster\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=3e-5,                        # Slightly higher - faster convergence\n",
    "    per_device_train_batch_size=64,           # Larger batch - much faster\n",
    "    per_device_eval_batch_size=128,           # Max out eval batch\n",
    "    num_train_epochs=1,                        # Single pass is enough\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=200,                         # Less frequent logging\n",
    "    load_best_model_at_end=False,             # Skip loading - saves time\n",
    "    save_total_limit=1,\n",
    "    report_to=\"none\",                          # Disable reporting overhead\n",
    "    warmup_ratio=0.1,                          # 10% warmup - helps convergence\n",
    "    fp16=True,                                 # Force mixed precision\n",
    "    dataloader_num_workers=2,                 # Parallel data loading\n",
    "    gradient_accumulation_steps=1,            # No accumulation needed with large batch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T01:05:44.126822Z",
     "iopub.status.busy": "2025-10-13T01:05:44.126545Z",
     "iopub.status.idle": "2025-10-13T01:05:44.131895Z",
     "shell.execute_reply": "2025-10-13T01:05:44.131011Z",
     "shell.execute_reply.started": "2025-10-13T01:05:44.126801Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"\n",
    "    Compute evaluation metrics\n",
    "    \"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = (predictions == labels).mean()\n",
    "    \n",
    "    # Calculate precision, recall, and F1\n",
    "    from sklearn.metrics import precision_recall_fscore_support\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, predictions, average='binary'\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T01:05:47.698841Z",
     "iopub.status.busy": "2025-10-13T01:05:47.698564Z",
     "iopub.status.idle": "2025-10-13T01:05:47.711441Z",
     "shell.execute_reply": "2025-10-13T01:05:47.710665Z",
     "shell.execute_reply.started": "2025-10-13T01:05:47.698819Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_dataset['train'],\n",
    "    eval_dataset=encoded_dataset['validation'],\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Fine Tuning & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T01:05:51.390142Z",
     "iopub.status.busy": "2025-10-13T01:05:51.389823Z",
     "iopub.status.idle": "2025-10-13T01:14:15.167669Z",
     "shell.execute_reply": "2025-10-13T01:14:15.166959Z",
     "shell.execute_reply.started": "2025-10-13T01:05:51.390107Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='310' max='310' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [310/310 08:20, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.092300</td>\n",
       "      <td>0.007534</td>\n",
       "      <td>0.997979</td>\n",
       "      <td>0.998898</td>\n",
       "      <td>0.995607</td>\n",
       "      <td>0.997250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed!\n",
      "Training time: 503.25 seconds\n",
      "Training samples per second: 39.32\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "train_result = trainer.train()\n",
    "\n",
    "# Print training results\n",
    "print(\"\\nTraining completed!\")\n",
    "print(f\"Training time: {train_result.metrics['train_runtime']:.2f} seconds\")\n",
    "print(f\"Training samples per second: {train_result.metrics['train_samples_per_second']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T01:14:34.125643Z",
     "iopub.status.busy": "2025-10-13T01:14:34.124877Z",
     "iopub.status.idle": "2025-10-13T01:16:36.772907Z",
     "shell.execute_reply": "2025-10-13T01:16:36.772029Z",
     "shell.execute_reply.started": "2025-10-13T01:14:34.125616Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Results:\n",
      "eval_loss: 0.0075\n",
      "eval_accuracy: 0.9980\n",
      "eval_precision: 0.9989\n",
      "eval_recall: 0.9956\n",
      "eval_f1: 0.9972\n",
      "eval_runtime: 37.6194\n",
      "eval_samples_per_second: 131.5010\n",
      "eval_steps_per_second: 1.0370\n",
      "epoch: 1.0000\n",
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "Test predictions generated!\n",
      "\n",
      "Generating predictions for detailed analysis...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign       1.00      1.00      1.00      3126\n",
      "   Malicious       1.00      1.00      1.00      1821\n",
      "\n",
      "    accuracy                           1.00      4947\n",
      "   macro avg       1.00      1.00      1.00      4947\n",
      "weighted avg       1.00      1.00      1.00      4947\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3124    2]\n",
      " [   8 1813]]\n",
      "\n",
      "[TN  FP]\n",
      "[FN  TP]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on validation set\n",
    "eval_results = trainer.evaluate()\n",
    "print(\"\\nValidation Results:\")\n",
    "for key, value in eval_results.items():\n",
    "    print(f\"{key}: {value:.4f}\")\n",
    "\n",
    "# Get predictions on test set (if available)\n",
    "if 'test' in encoded_dataset and len(encoded_dataset['test']) > 0:\n",
    "    print(\"\\nEvaluating on test set...\")\n",
    "    predictions = trainer.predict(encoded_dataset['test'])\n",
    "    predicted_labels = np.argmax(predictions.predictions, axis=1)\n",
    "    \n",
    "    # Note: GLUE SST2 test set doesn't have labels\n",
    "    # If using a custom dataset with test labels, you can compute metrics\n",
    "    print(\"\\nTest predictions generated!\")\n",
    "\n",
    "# Get predictions on validation set for detailed analysis\n",
    "print(\"\\nGenerating predictions for detailed analysis...\")\n",
    "val_predictions = trainer.predict(encoded_dataset['validation'])\n",
    "val_predicted_labels = np.argmax(val_predictions.predictions, axis=1)\n",
    "val_true_labels = encoded_dataset['validation']['label']\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    val_true_labels, \n",
    "    val_predicted_labels,\n",
    "    target_names=['Benign', 'Malicious']\n",
    "))\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(val_true_labels, val_predicted_labels)\n",
    "print(cm)\n",
    "print(\"\\n[TN  FP]\")\n",
    "print(\"[FN  TP]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T01:17:01.279182Z",
     "iopub.status.busy": "2025-10-13T01:17:01.278828Z",
     "iopub.status.idle": "2025-10-13T01:17:01.897009Z",
     "shell.execute_reply": "2025-10-13T01:17:01.896231Z",
     "shell.execute_reply.started": "2025-10-13T01:17:01.279150Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing on SQL queries:\n",
      "\n",
      "SQL Query: SELECT * FROM users WHERE username = 'admin'\n",
      "Classification: Benign (Confidence: 99.88%)\n",
      "\n",
      "SQL Query: SELECT * FROM users WHERE id = 1 OR 1=1--\n",
      "Classification: Malicious (Confidence: 99.89%)\n",
      "\n",
      "SQL Query: SELECT name, email FROM customers WHERE id = 5\n",
      "Classification: Benign (Confidence: 99.82%)\n",
      "\n",
      "SQL Query: '; DROP TABLE users; --\n",
      "Classification: Malicious (Confidence: 99.88%)\n",
      "\n",
      "SQL Query: SELECT * FROM products WHERE category = 'electronics' AND price < 100\n",
      "Classification: Benign (Confidence: 99.89%)\n",
      "\n",
      "SQL Query: 1' UNION SELECT null, table_name FROM information_schema.tables--\n",
      "Classification: Malicious (Confidence: 99.89%)\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model for inference\n",
    "# Load from checkpoint\n",
    "inference_model = DistilBertForSequenceClassification.from_pretrained(\"./results/checkpoint-310\")\n",
    "inference_tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# inference_model = DistilBertForSequenceClassification.from_pretrained(\"./fine_tuned_distilbert\")\n",
    "# inference_tokenizer = DistilBertTokenizer.from_pretrained(\"./fine_tuned_distilbert\")\n",
    "\n",
    "inference_model.to(device)\n",
    "inference_model.eval()\n",
    "\n",
    "# Test SQL queries\n",
    "test_sentences = [\n",
    "    \"SELECT * FROM users WHERE username = 'admin'\",\n",
    "    \"SELECT * FROM users WHERE id = 1 OR 1=1--\",\n",
    "    \"SELECT name, email FROM customers WHERE id = 5\",\n",
    "    \"'; DROP TABLE users; --\",\n",
    "    \"SELECT * FROM products WHERE category = 'electronics' AND price < 100\",\n",
    "    \"1' UNION SELECT null, table_name FROM information_schema.tables--\"\n",
    "]\n",
    "\n",
    "print(\"\\nTesting on SQL queries:\")\n",
    "for sentence in test_sentences:\n",
    "    # Tokenize\n",
    "    inputs = inference_tokenizer(\n",
    "        sentence, \n",
    "        return_tensors=\"pt\", \n",
    "        padding=True, \n",
    "        truncation=True, \n",
    "        max_length=512\n",
    "    )\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        outputs = inference_model(**inputs)\n",
    "        prediction = torch.argmax(outputs.logits, dim=1).item()\n",
    "        probabilities = torch.nn.functional.softmax(outputs.logits, dim=1)[0]\n",
    "    \n",
    "    sentiment = \"Malicious\" if prediction == 1 else \"Benign\"\n",
    "    confidence = probabilities[prediction].item() * 100\n",
    "    \n",
    "    print(f\"\\nSQL Query: {sentence}\")\n",
    "    print(f\"Classification: {sentiment} (Confidence: {confidence:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T01:17:15.602096Z",
     "iopub.status.busy": "2025-10-13T01:17:15.601337Z",
     "iopub.status.idle": "2025-10-13T01:17:16.219143Z",
     "shell.execute_reply": "2025-10-13T01:17:16.218331Z",
     "shell.execute_reply.started": "2025-10-13T01:17:15.602070Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/kaggle/working/sqli_detector_model/tokenizer_config.json',\n",
       " '/kaggle/working/sqli_detector_model/special_tokens_map.json',\n",
       " '/kaggle/working/sqli_detector_model/vocab.txt',\n",
       " '/kaggle/working/sqli_detector_model/added_tokens.json')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save with clean name\n",
    "model.save_pretrained(\"/kaggle/working/sqli_detector_model\")\n",
    "tokenizer.save_pretrained(\"/kaggle/working/sqli_detector_model\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1579031,
     "sourceId": 2598516,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
